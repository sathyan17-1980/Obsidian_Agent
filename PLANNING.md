# Planning Documentation - Master Index

**Feature**: Obsidian Folder Management Enhancement
**Status**: Planning Complete, Ready for Implementation
**Total Documentation**: 10 files, ~8,000+ lines
**Total Tests**: 169 (157 automated + 12 manual)

---

## ðŸ“‹ Quick Navigation

| What You Need | Go To |
|---------------|-------|
| **Start implementing now** | [Implementation Sequence](#2-implementation-sequence) â†’ COMPLETE-COMPONENT-TESTING-CHECKLIST.md |
| **Understand the planning approach** | [Learning Sequence](#1-learning-sequence) |
| **Run pre-deployment validation** | [Pre-Deployment Sequence](#3-pre-deployment-sequence) â†’ PRE-DEPLOYMENT-VALIDATION-SUMMARY.md |
| **Deploy to production** | [Deployment Sequence](#4-deployment-sequence) â†’ DEPLOYMENT-VALIDATION-STRATEGY.md |
| **Monitor after deployment** | [Post-Deployment Sequence](#5-post-deployment-sequence) â†’ POST-DEPLOYMENT-VALIDATION-STRATEGY.md |
| **Quick command reference** | [Quick Reference Table](#quick-reference-table) |
| **See all documents** | [All Documents Summary](#all-documents-summary) |

---

## All Documents Summary

### Core Planning (3 files)

#### 1. IMPLEMENTATION-PLAN-TEMPLATE.md (~600 lines)
**Purpose**: Reusable planning framework for any future feature

**Key Sections**:
- 12 comprehensive planning sections
- Meta information (Feature ID, owner, status, priority)
- Goal & Problem Statement with measurable metrics
- User Stories with personas and acceptance criteria
- Task Breakdown with Definition of Done
- Success Criteria, Validation Strategy, Risk Assessment

**When to Use**: Planning any new feature or enhancement

**Reading Time**: 30 minutes

---

#### 2. PLANNING-IMPROVEMENTS.md (~450 lines)
**Purpose**: Gap analysis of what was missing from original plan

**Key Sections**:
- 8 major missing elements identified
- Comparison: Before vs After
- Why each element matters
- 10 additional considerations (security, observability, performance, etc.)

**When to Use**: Understanding why comprehensive planning matters, learning from mistakes

**Reading Time**: 20 minutes

---

#### 3. FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md (~900 lines)
**Purpose**: Main implementation plan for this feature

**Key Sections**:
1. Goal & Problem Statement
   - Reduce LLM tool confusion from 20% â†’ <5%
   - Target >95% tool selection accuracy
2. User Stories (2 stories)
   - US1: Clear Tool Separation (P0 - Must Have)
   - US2: Archive Old Projects with auto-dating
3. Success Criteria (quantifiable metrics)
4. Current State Analysis
5. Proposed Solution (6-layer separation strategy)
6. Tasks (20+ tasks across 4 phases with Definition of Done)
7. Validation Strategy
8. Risks & Mitigations

**When to Use**: Primary reference during implementation

**Reading Time**: 45 minutes (full), 15 minutes (Sections 1-3 only)

---

### Testing & Validation (7 files)

#### 4. TESTING-AND-VALIDATION-STRATEGY.md (~1,500 lines)
**Purpose**: Complete technical testing specifications for all 169 tests

**Key Sections**:
- **Section 1: Pre-Deployment Validation** (5 phases, 20+ checks)
  - 1.1 Dependency Validation âœ…
  - 1.2 Linting and Type Checking (ruff >=0.14.0, mypy >=1.18.2) âœ…
  - 1.3 Unit Tests (pytest >=8.4.2, >90% coverage) âœ…
  - 1.4 Integration Tests âœ…
  - 1.5 Security Tests âœ…
- **Section 2: Unit Tests** (30+ tests)
- **Section 3: Integration Tests** (10 tests)
- **Section 4: End-to-End Tests** (2 tests)
- **Section 5: Tool Evaluation Tests** (50 tests)
- **Section 6: Platform Integration Tests** (9 tests)
- **Section 7: Performance Tests** (6 tests)
- **Section 8: Security Tests** (6 tests)
- **Section 9: Regression Tests** (20 existing tests)

**When to Use**: Reference for detailed test specifications, troubleshooting test failures

**Reading Time**: 60 minutes (full), 20 minutes (Section 1 only)

---

#### 5. PRE-DEPLOYMENT-VALIDATION-SUMMARY.md (~530 lines)
**Purpose**: Quick reference for all pre-deployment validation

**Key Sections**:
- All 5 validation phases with commands
- Success criteria for each check
- Estimated time for each phase
- Complete command reference

**Example Commands**:
```bash
# 1.2 Linting and Type Checking
uv run ruff check src/tools/obsidian_folder_manager/
uv run mypy src/tools/obsidian_folder_manager/ --strict

# 1.3 Unit Tests
uv run pytest tests/tools/obsidian_folder_manager/ -v -m unit \
    --cov=src/tools/obsidian_folder_manager/ \
    --cov-fail-under=90
```

**When to Use**: Running pre-deployment validation before merging

**Reading Time**: 15 minutes

---

#### 6. DEPLOYMENT-VALIDATION-STRATEGY.md (~900 lines)
**Purpose**: 4-stage deployment process with validation at each stage

**Key Sections**:
- **Stage 1**: Local/Dev Environment â†’ Smoke Tests
- **Stage 2**: Staging Environment â†’ Integration Validation (15 min user verification)
- **Stage 3**: Canary Deployment (5% traffic) â†’ 24-hour monitoring
- **Stage 4**: Full Production (25% â†’ 50% â†’ 100%) â†’ 2-3 day rollout
- Rollback procedures for each stage
- Deployment checklist
- Monitoring and alerting setup

**When to Use**: When ready to deploy to production

**Reading Time**: 40 minutes

---

#### 7. POST-DEPLOYMENT-VALIDATION-STRATEGY.md (~800 lines)
**Purpose**: 30-day monitoring strategy after production release

**Key Sections**:
- Day 1-7: Intensive monitoring (daily checks)
- Week 2-4: Weekly check-ins
- Ongoing: Monthly reviews
- Production metrics and targets
  - Archive operation success rate >99%
  - Tool selection accuracy >95%
  - P95 latency <200ms
- Automated smoke tests (every 6 hours)
- Incident response procedures
- Success criteria for full rollout completion

**When to Use**: After production deployment for monitoring

**Reading Time**: 35 minutes

---

#### 8. MANUAL-TESTING-GUIDE.md (~700 lines)
**Purpose**: Your specific involvement and time commitment

**Key Sections**:
- **Section 1**: Your Time Commitment Summary
  - MINIMUM (Must Do): 55 minutes total
    - UAT (30 min) - Test feature, sign off
    - Staging verification (15 min) - Approve for production
    - Production Day 1 smoke test (10 min)
  - RECOMMENDED: 125 minutes (adds 4 weekly check-ins @ 10 min each)
  - CAN DELEGATE: Clearly marked tasks

- **Section 2**: User Acceptance Testing (UAT) - 30 minutes
  - 6 detailed test scenarios with step-by-step instructions
  - Pass/Fail criteria for each test

- **Section 3**: Post-Deployment Testing
  - Staging verification (15 min)
  - Production Day 1 smoke test (10 min)
  - Weekly monitoring check-ins (4 Ã— 10 min)

**When to Use**: When you need to perform manual testing

**Reading Time**: 25 minutes

---

#### 9. FULL-TEST-SUITE-OVERVIEW.md (~800 lines)
**Purpose**: Master overview of all 169 tests

**Key Sections**:
- Complete test summary table by category
- Test distribution breakdown
- All validation commands in one place
- Test execution sequence
- Coverage requirements
- How all test documents relate to each other

**Test Summary**:
| Category | Automated | Manual | Total |
|----------|-----------|--------|-------|
| Pre-Deployment | 48 | 5 UAT | 53 |
| Deployment | 12 smoke | 2 verifications | 14 |
| Post-Deployment | 6 monitors | 4 check-ins | 10 |
| Evaluation | 50 | - | 50 |
| Platform | 9 | - | 9 |
| Performance | 6 | - | 6 |
| Security | 6 | - | 6 |
| Regression | 20 | - | 20 |
| **TOTAL** | **157** | **12** | **169** |

**When to Use**: Understanding the complete testing landscape

**Reading Time**: 30 minutes

---

#### 10. COMPLETE-COMPONENT-TESTING-CHECKLIST.md (~1,000 lines) â­ **PRIMARY IMPLEMENTATION GUIDE**
**Purpose**: Step-by-step guide ensuring all components tested and all tests pass

**Key Sections**:
- **Section 1**: Component Coverage Matrix
  - All 19 components mapped to test files
  - 4 Models/Schemas, 5 Services, 4 Tools, 2 APIs, 4 Integrations

- **Section 2**: Complete Test Writing Plan (70 tests)
  - 50 new tests + 20 existing = 70 total
  - Exact code skeletons for all 9 test files
  - Each test marked with "â˜ WRITE THIS TEST"

- **Section 3**: Complete Validation Commands
  - Every command documented with expected outputs
  - Component-by-component validation sequence

- **Section 4**: Ensuring All Tests Pass
  - 12-step validation checklist
  - Success criteria: 70/70 tests pass, >90% coverage, 0 type errors, 0 linting errors
  - Failure handling procedures with common error patterns

- **Section 5**: Implementation Timeline
  - Week-by-week breakdown

- **Section 6**: Final Pre-Deployment Checklist

**When to Use**: Your primary guide during implementation - follow this step-by-step

**Reading Time**: 40 minutes (full), 20 minutes (Sections 1-2 only)

---

## Reading Sequences

### 1. Learning Sequence (Understanding the Planning Approach)

**Purpose**: Understand why this plan was created and how it's structured

**Time**: ~45 minutes

```
Step 1: PLANNING-IMPROVEMENTS.md (20 min)
        â†“
        What was missing from original plan
        â†“

Step 2: IMPLEMENTATION-PLAN-TEMPLATE.md (15 min)
        â†“
        Framework used for all planning
        â†“

Step 3: FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md (Sections 1-3 only) (10 min)
        â†“
        Main implementation plan - Goal, User Stories, Success Criteria
        â†“

Step 4: FULL-TEST-SUITE-OVERVIEW.md (10 min)
        â†“
        Master overview of all 169 tests
```

**Outcome**: Complete understanding of planning approach and structure

---

### 2. Implementation Sequence (Development Phase)

**Purpose**: Write code and tests following TDD approach

**Time**: Follow over 2-3 weeks of development

```
Step 1: FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md (15 min)
        â†“
        Read Sections 1-3: Goal, User Stories, Success Criteria
        â†“

Step 2: COMPLETE-COMPONENT-TESTING-CHECKLIST.md â­ PRIMARY GUIDE (20 min initial read)
        â†“
        Section 1: Component Coverage Matrix (understand all components)
        Section 2: Test Writing Plan (follow step-by-step)
        Section 3: Validation Commands (run after each component)
        Section 4: Ensuring All Tests Pass (final validation)
        â†“

        [During Implementation - Keep Open as Reference]
        â”‚
        â”œâ”€â†’ TESTING-AND-VALIDATION-STRATEGY.md
        â”‚   (Reference for detailed test specifications)
        â”‚
        â”œâ”€â†’ PRE-DEPLOYMENT-VALIDATION-SUMMARY.md
        â”‚   (Quick command reference)
        â”‚
        â””â”€â†’ FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md
            (Section 6: Tasks - follow Definition of Done)
```

**Workflow**:
1. Read component from COMPLETE-COMPONENT-TESTING-CHECKLIST.md Section 1
2. Write test from Section 2 code skeleton
3. Run validation command from Section 3
4. Mark component complete when tests pass
5. Repeat for all 19 components
6. Final validation using Section 4 (12-step checklist)

**Outcome**: All code written, all 70 tests passing, ready for deployment

---

### 3. Pre-Deployment Sequence (Before Merging to Main)

**Purpose**: Ensure all quality gates pass before deployment

**Time**: ~2-3 hours

```
Step 1: PRE-DEPLOYMENT-VALIDATION-SUMMARY.md â­ PRIMARY (15 min read + 2 hours execution)
        â†“
        Run all 5 validation phases:
        1.1 Dependency Validation (5 min)
        1.2 Linting and Type Checking (5 min)
        1.3 Unit Tests (30 min)
        1.4 Integration Tests (15 min)
        1.5 Security Tests (10 min)
        â†“

Step 2: COMPLETE-COMPONENT-TESTING-CHECKLIST.md
        â†“
        Section 4: 12-step validation checklist
        â†“

        [If Any Validation Fails]
        â†“
        TESTING-AND-VALIDATION-STRATEGY.md
        â†“
        Section 1: Pre-Deployment Validation (detailed troubleshooting)
        â†“

Step 3: FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md
        â†“
        Section 7: Validation Strategy - Verify all Quality Gates pass
```

**Success Criteria**:
- âœ… 70/70 tests pass (100% pass rate)
- âœ… Coverage >90%
- âœ… MyPy 0 errors (strict mode)
- âœ… Ruff 0 errors
- âœ… Bandit 0 high/medium vulnerabilities

**Outcome**: Code ready to merge and deploy

---

### 4. Deployment Sequence (Releasing to Production)

**Purpose**: Deploy safely with validation at each stage

**Time**: 3-5 days for full deployment rollout

```
Step 1: DEPLOYMENT-VALIDATION-STRATEGY.md â­ PRIMARY (40 min read + 3-5 days execution)
        â†“
        Stage 1: Local/Dev Environment (30 min)
        â”œâ”€ Run smoke tests
        â””â”€ Verify all systems operational
        â†“

        Stage 2: Staging Environment (1 day)
        â”œâ”€ Deploy to staging
        â”œâ”€ Run integration validation
        â””â”€ USER ACTION REQUIRED (15 min) â†“
        â†“

Step 2: MANUAL-TESTING-GUIDE.md
        â†“
        Section 3.1: Staging Verification (15 min)
        â”œâ”€ Test 5 key scenarios
        â”œâ”€ Sign off for production deployment
        â””â”€ Approval given âœ…
        â†“

        [Return to DEPLOYMENT-VALIDATION-STRATEGY.md]
        â†“

        Stage 3: Canary Deployment (1 day)
        â”œâ”€ Deploy to 5% of production traffic
        â”œâ”€ 24-hour monitoring
        â””â”€ Verify no regressions
        â†“

        Stage 4: Full Production (2-3 days)
        â”œâ”€ Deploy to 25% traffic (monitor 24h)
        â”œâ”€ Deploy to 50% traffic (monitor 24h)
        â”œâ”€ Deploy to 100% traffic (monitor 48h)
        â””â”€ USER ACTION REQUIRED (10 min) â†“
        â†“

Step 3: MANUAL-TESTING-GUIDE.md
        â†“
        Section 3.2: Production Day 1 Smoke Test (10 min)
        â”œâ”€ Verify feature works in production
        â””â”€ Confirm no errors
```

**Outcome**: Feature successfully deployed to 100% production traffic

---

### 5. Post-Deployment Sequence (After Production Release)

**Purpose**: Monitor production and ensure success

**Time**: 30 days of monitoring (70 min user involvement recommended)

```
Step 1: POST-DEPLOYMENT-VALIDATION-STRATEGY.md â­ PRIMARY (35 min read + 30 days monitoring)
        â†“
        Day 1-7: Intensive Monitoring
        â”œâ”€ Daily automated smoke tests (6 hours interval)
        â”œâ”€ Monitor metrics dashboard
        â”œâ”€ Check error rates, latency, success rates
        â””â”€ USER ACTION REQUIRED (10 min weekly) â†“
        â†“

Step 2: MANUAL-TESTING-GUIDE.md
        â†“
        Section 3.2: Weekly Check-ins (4 Ã— 10 min over 4 weeks)
        â”œâ”€ Week 1: Review metrics, test archive feature
        â”œâ”€ Week 2: Spot check tool selection accuracy
        â”œâ”€ Week 3: Review error logs
        â””â”€ Week 4: Final validation, declare success
        â†“

        [Return to POST-DEPLOYMENT-VALIDATION-STRATEGY.md]
        â†“

        Week 2-4: Weekly Monitoring
        â”œâ”€ Weekly metrics reviews
        â”œâ”€ Performance trend analysis
        â””â”€ Issue tracking
        â†“

        Ongoing: Monthly Reviews
        â”œâ”€ Success criteria validation
        â””â”€ Continuous improvement
```

**Success Criteria** (from POST-DEPLOYMENT-VALIDATION-STRATEGY.md):
- âœ… Archive operation success rate >99%
- âœ… Tool selection accuracy >95%
- âœ… P95 latency <200ms
- âœ… 0 critical incidents
- âœ… User satisfaction with archive feature

**Outcome**: Feature stable in production, all success criteria met

---

## Quick Reference Table

| What You Need | File to Open | Section |
|---------------|-------------|---------|
| **"What component do I test next?"** | COMPLETE-COMPONENT-TESTING-CHECKLIST.md | Section 1: Component Coverage Matrix |
| **"What's the exact test code to write?"** | COMPLETE-COMPONENT-TESTING-CHECKLIST.md | Section 2: Test Writing Plan |
| **"What command do I run now?"** | PRE-DEPLOYMENT-VALIDATION-SUMMARY.md | All sections |
| **"Did all tests pass?"** | COMPLETE-COMPONENT-TESTING-CHECKLIST.md | Section 4: 12-step checklist |
| **"What's the next task to implement?"** | FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md | Section 6: Tasks |
| **"What are the success criteria?"** | FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md | Section 3: Success Criteria |
| **"How do I deploy?"** | DEPLOYMENT-VALIDATION-STRATEGY.md | All stages |
| **"What do I test manually?"** | MANUAL-TESTING-GUIDE.md | Section 2: UAT |
| **"What are the production metrics?"** | POST-DEPLOYMENT-VALIDATION-STRATEGY.md | Section 2: Metrics |
| **"How do I troubleshoot test failures?"** | TESTING-AND-VALIDATION-STRATEGY.md | Specific test section |
| **"What's the overall test count?"** | FULL-TEST-SUITE-OVERVIEW.md | Test Summary Table |

---

## Minimum Viable Reading (Start Fastest)

**If you only read 3 files before starting implementation:**

```
1. COMPLETE-COMPONENT-TESTING-CHECKLIST.md (20 min) â­ START HERE
   â†“ Your step-by-step implementation guide

2. FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md (Sections 1-3 only) (15 min)
   â†“ Goal, User Stories, Success Criteria

3. MANUAL-TESTING-GUIDE.md (Section 2: UAT) (10 min)
   â†“ What you'll need to test
```

**Total**: 45 minutes, then start implementing following COMPLETE-COMPONENT-TESTING-CHECKLIST.md Section 2

---

## Document Dependencies (Visual Flow)

```
IMPLEMENTATION-PLAN-TEMPLATE.md (Framework)
         â†“
         â†“ (template for)
         â†“
FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md â†â”€â”€â”
         â†“                                â”‚
         â†“                                â”‚ (references)
         â†“                                â”‚
TESTING-AND-VALIDATION-STRATEGY.md â”€â”€â”€â”€â”€â”€â”˜
         â†“
         â†“ (summarized in)
         â†“
PRE-DEPLOYMENT-VALIDATION-SUMMARY.md
         â†“
         â†“ (feeds into)
         â†“
COMPLETE-COMPONENT-TESTING-CHECKLIST.md â­ PRIMARY GUIDE
         â†“
         â†“ (after tests pass)
         â†“
DEPLOYMENT-VALIDATION-STRATEGY.md
         â†“
         â†“ (uses)
         â†“
MANUAL-TESTING-GUIDE.md
         â†“
         â†“ (after deployment)
         â†“
POST-DEPLOYMENT-VALIDATION-STRATEGY.md
         â†“
         â†“ (everything summarized in)
         â†“
FULL-TEST-SUITE-OVERVIEW.md (Master Overview)

PLANNING-IMPROVEMENTS.md (Lessons Learned - standalone)
```

---

## Implementation Checklist

Use this as your high-level progress tracker:

```
Planning Phase:
â˜ Read COMPLETE-COMPONENT-TESTING-CHECKLIST.md (Sections 1-2)
â˜ Read FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md (Sections 1-3)
â˜ Understand all 19 components to be implemented
â˜ Review all 70 tests to be written

Implementation Phase (2-3 weeks):
â˜ Phase 1: Schema Changes (5 tests)
â˜ Phase 2: Service Implementation (13 tests)
â˜ Phase 3: Tool Integration (4 tests)
â˜ Phase 4: Error Handling (8 tests)
â˜ Phase 5: Wikilink Updates (6 tests)
â˜ Phase 6: Cross-Component (10 tests)
â˜ Phase 7: Security & Workflows (8 tests)

Pre-Deployment Validation (2-3 hours):
â˜ Run all validations from PRE-DEPLOYMENT-VALIDATION-SUMMARY.md
â˜ Complete 12-step checklist from COMPLETE-COMPONENT-TESTING-CHECKLIST.md Section 4
â˜ Verify 70/70 tests pass, >90% coverage, 0 type errors, 0 linting errors

Deployment Phase (3-5 days):
â˜ Stage 1: Local/Dev deployment + smoke tests
â˜ Stage 2: Staging deployment + 15 min UAT verification
â˜ Stage 3: Canary deployment (5% traffic) + 24h monitoring
â˜ Stage 4: Production rollout (25% â†’ 50% â†’ 100%)
â˜ Production Day 1 smoke test (10 min)

Post-Deployment Monitoring (30 days):
â˜ Day 1-7: Daily monitoring
â˜ Week 1 check-in (10 min)
â˜ Week 2 check-in (10 min)
â˜ Week 3 check-in (10 min)
â˜ Week 4 check-in + final validation (10 min)
â˜ Verify all success criteria met (>99% success rate, >95% accuracy, <200ms latency)
â˜ Declare feature complete âœ…
```

---

## Key Success Metrics

**From FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md Section 3:**

| Metric | Current | Target | How to Measure |
|--------|---------|--------|----------------|
| Tool Selection Accuracy | ~80% | >95% | Tool evaluation tests (50 tests) |
| Archive Success Rate | N/A | >99% | Production metrics |
| Test Coverage | ~85% | >90% | pytest-cov |
| Type Safety | Some `Any` | 0 `Any` | mypy --strict |
| P95 Latency | Unknown | <200ms | Production monitoring |

---

## Total Time Investment

| Phase | Development Time | User Time (Minimum) | User Time (Recommended) |
|-------|------------------|---------------------|-------------------------|
| Planning Review | - | 45 min | 90 min |
| Implementation | 80-120 hours | - | - |
| Pre-Deployment | 2-3 hours | - | - |
| Deployment | 3-5 days | 25 min | 25 min |
| Post-Deployment | - | 10 min | 70 min |
| **TOTAL** | **2-3 weeks** | **80 min (1h 20m)** | **185 min (3h 5m)** |

**User's Minimum Commitment**: 80 minutes over 5 weeks
**User's Recommended Commitment**: 185 minutes (3 hours) over 5 weeks

---

## Next Steps

**You are here**: Planning Complete, Ready for Implementation

**Recommended Next Action**:

1. Read COMPLETE-COMPONENT-TESTING-CHECKLIST.md (20 min)
2. Begin Phase 1: Schema Changes following Section 2
3. Write first 5 tests from test_schemas.py
4. Run validation: `uv run pytest test_schemas.py -v`
5. Continue component-by-component

**Questions Before Starting?**
- Review MANUAL-TESTING-GUIDE.md Section 1 to understand your time commitment
- Review FOLDER-MANAGEMENT-ENHANCEMENT-PLAN.md Section 3 for success criteria
- Review FULL-TEST-SUITE-OVERVIEW.md for complete testing landscape

---

## Document Maintenance

**Last Updated**: 2025-01-22
**Git Branch**: `claude/review-agent-core-01E8UdzqkJNLQKTxMGeeR8rK`
**Status**: All documents committed and pushed

**When to Update This Document**:
- New .md files added to planning
- Sequences change based on lessons learned
- Additional reading paths identified
- Success metrics updated

---

## Additional Resources

**Project Documentation**:
- CLAUDE.md - AI Agent Development Instructions (coding standards, logging, testing requirements)
- README.md - Project overview and setup
- coding-agent.md - Original implementation plan (superseded by this planning)

**External References**:
- FastAPI Documentation: https://fastapi.tiangolo.com/
- Pydantic AI Documentation: https://ai.pydantic.dev/
- Pytest Documentation: https://docs.pytest.org/
- MyPy Documentation: https://mypy.readthedocs.io/
- Ruff Documentation: https://docs.astral.sh/ruff/

---

**Ready to begin implementation? Start with COMPLETE-COMPONENT-TESTING-CHECKLIST.md** â­
